{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9_6Bn5YYkPf"
      },
      "source": [
        "# 08 - Transformer Encoder-Decoder\n",
        "\n",
        "Neste notebook, vamos implementar um modelo encoder-decoder baseado no **Transformer**, uma arquitetura que substituiu as RNNs em muitas tarefas de NLP e se tornou o padrão em tradução automática e modelos de linguagem modernos.\n",
        "\n",
        "## Objetivos de Aprendizado\n",
        "- Revisar a arquitetura do Transformer e seus principais componentes (Self-Attention, Encoder, Decoder)\n",
        "- Implementar o Encoder e o Decoder com PyTorch\n",
        "- Construir um modelo completo de tradução português-inglês usando Transformer\n",
        "- Treinar o modelo em um conjunto de dados de exemplo\n",
        "- Avaliar a qualidade das traduções geradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vaRzxrPXyIQR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fCMIS7t82sou"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_56CNHmCYkPk"
      },
      "source": [
        "### Positional Encoding\n",
        "\n",
        "Transformers não possuem mecanismos recorrentes ou convolucionais, o que significa que eles não têm uma noção implícita da ordem dos tokens em uma sequência. Para incorporar essa informação, é adicionada uma codificação posicional aos vetores de embedding. Essa codificação é determinística e baseada em funções senoidais de diferentes frequências.\n",
        "\n",
        "A codificação posicional utilizada segue a formulação original do paper *\"Attention is All You Need\"*:\n",
        "\n",
        "$$\n",
        "PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $pos$ representa a posição do token na sequência,\n",
        "- $i$ é o índice da dimensão do embedding,\n",
        "- $d_{\\text{model}}$ é a dimensionalidade do embedding.\n",
        "\n",
        "O resultado é uma matriz de codificação com forma $(1, \\text{max\\_len}, d_{\\text{model}})$ que é somada diretamente aos embeddings de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kgc8jL8RYkPl"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # matriz (max_len, d_model)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # seno nas posições pares, cosseno nas ímpares\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # pares\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # ímpares\n",
        "\n",
        "        pe = pe.unsqueeze(0)  # (1, max_len, d_model) -> broadcast no batch\n",
        "        self.register_buffer(\"pe\", pe)  # não é parâmetro treinável\n",
        "\n",
        "    def forward(self, x):\n",
        "        T = x.size(1)\n",
        "        x = x + self.pe[:, :T, :]  # (B, T, d_model)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0D6x5y2YkPl",
        "outputId": "9a1d61c9-5237-444e-afcc-bd361288b8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional Encoding: torch.Size([2, 5, 16])\n"
          ]
        }
      ],
      "source": [
        "d_model = 16\n",
        "num_heads = 4\n",
        "B, T = 2, 5\n",
        "\n",
        "# embeddings simulados\n",
        "x = torch.randn(B, T, d_model)\n",
        "\n",
        "# positional encoding\n",
        "pos_enc = PositionalEncoding(d_model)\n",
        "x = pos_enc(x)  # adiciona posições\n",
        "\n",
        "print(\"Positional Encoding:\", x.shape)  # (B, T, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHkyPwYmYkPm"
      },
      "source": [
        "### Multi-Head Attention\n",
        "\n",
        "O mecanismo de **multi-head attention** é um dos blocos centrais dos Transformers. Ele permite que o modelo foque em diferentes partes da sequência em paralelo, usando múltiplas \"cabeças\" de atenção. Cada cabeça realiza uma atenção com projeções diferentes dos vetores de entrada, e seus resultados são combinados ao final.\n",
        "\n",
        "A atenção é baseada no mecanismo de **Scaled Dot-Product Attention**, que recebe três vetores: $Q$ (query), $K$ (key) e $V$ (value). O cálculo da atenção segue a fórmula:\n",
        "\n",
        "$$\n",
        "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $Q$, $K$ e $V$ são tensores projetados a partir da entrada,\n",
        "- $d_k$ é a dimensionalidade das chaves (key),\n",
        "- A divisão por $\\sqrt{d_k}$ serve para normalizar os scores e evitar valores muito grandes que podem saturar a softmax.\n",
        "\n",
        "No caso de múltiplas cabeças, os vetores $Q$, $K$ e $V$ são divididos em $h$ partes (cabeças), cada uma com dimensionalidade reduzida $d_k = d_{\\text{model}} / h$, aplicando a atenção de forma independente em cada cabeça. Os resultados são então concatenados e projetados novamente com uma camada linear:\n",
        "\n",
        "$$\n",
        "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W^O\n",
        "$$\n",
        "\n",
        "Cada cabeça é computada como:\n",
        "\n",
        "$$\n",
        "\\text{head}_i = \\text{Attention}(Q W_i^Q, K W_i^K, V W_i^V)\n",
        "$$\n",
        "\n",
        "Esse paralelismo permite que diferentes aspectos contextuais da sequência sejam aprendidos simultaneamente. Essa implementação define todas as projeções lineares necessárias, faz o `split_heads`, aplica a atenção escalada, combina os resultados com `combine_heads`, e projeta de volta para o espaço original com uma camada linear $W^O$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "65qL10eEYkPm"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model deve ser divisível por num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "\n",
        "        # Projeções lineares\n",
        "        self.q_proj = nn.Linear(d_model, d_model)\n",
        "        self.k_proj = nn.Linear(d_model, d_model)\n",
        "        self.v_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        B, Tq, _ = q.size()\n",
        "        Tk = k.size(1)\n",
        "        Tv = v.size(1)\n",
        "\n",
        "        # Projeções\n",
        "        Q = self.q_proj(q)\n",
        "        K = self.k_proj(k)\n",
        "        V = self.v_proj(v)\n",
        "\n",
        "        # Split heads\n",
        "        Q = Q.view(B, Tq, self.num_heads, self.head_dim).transpose(1, 2)  # (B, h, Tq, d_head)\n",
        "        K = K.view(B, Tk, self.num_heads, self.head_dim).transpose(1, 2)  # (B, h, Tk, d_head)\n",
        "        V = V.view(B, Tv, self.num_heads, self.head_dim).transpose(1, 2)  # (B, h, Tv, d_head)\n",
        "\n",
        "        # Atenção\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)  # (B, h, Tq, Tk)\n",
        "\n",
        "        if mask is not None:\n",
        "            # mask: (B, 1, 1, Tk) ou (B, 1, Tq, Tk)\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, float(\"-inf\"))\n",
        "\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "        attn_output = torch.matmul(attn_weights, V)  # (B, h, Tq, d_head)\n",
        "\n",
        "        # Junta os heads\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, Tq, self.d_model)\n",
        "\n",
        "        return self.out_proj(attn_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QUUXbgYGYkPn"
      },
      "outputs": [],
      "source": [
        "def causal_mask(seq_len, device=None):\n",
        "    \"\"\"\n",
        "    Cria máscara causal triangular inferior.\n",
        "    shape: (1, 1, seq_len, seq_len)\n",
        "    \"\"\"\n",
        "    mask = torch.tril(torch.ones(seq_len, seq_len, device=device))\n",
        "    return mask.unsqueeze(0).unsqueeze(0)  # (1, 1, T, T)\n",
        "\n",
        "\n",
        "def padding_mask(pad_tokens, device=None):\n",
        "    \"\"\"\n",
        "    Cria máscara de padding.\n",
        "    pad_tokens: tensor (B, T) com 1 onde é token válido e 0 onde é padding\n",
        "    retorna shape: (B, 1, 1, T) -> broadcast em atenção\n",
        "    \"\"\"\n",
        "    return pad_tokens.unsqueeze(1).unsqueeze(2).to(device)  # (B,1,1,T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKftnuswYkPn",
        "outputId": "3ceb426c-65af-43a4-f0ec-1942428fa193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self-Attention: torch.Size([2, 5, 16])\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "d_model = 16\n",
        "num_heads = 4\n",
        "B, T = 2, 5\n",
        "\n",
        "x = torch.randn(B, T, d_model)\n",
        "mask = causal_mask(T, device=x.device)\n",
        "attn = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "\n",
        "out = attn(x, x, x, mask=mask)\n",
        "print(\"Self-Attention:\", out.shape)  # (B, T, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvzJ9YIGYkPo"
      },
      "source": [
        "### Feed-Forward Layer\n",
        "\n",
        "Em Transformers, cada bloco contém uma **camada feed-forward totalmente conectada** que é aplicada de forma independente a cada posição da sequência. Essa camada é responsável por aprender transformações não-lineares locais após o mecanismo de atenção.\n",
        "\n",
        "A arquitetura típica de uma feed-forward layer é composta por duas camadas lineares com uma função de ativação não-linear (geralmente ReLU) no meio:\n",
        "\n",
        "$$\n",
        "\\text{FFN}(x) = W_2 \\cdot \\text{ReLU}(W_1 \\cdot x + b_1) + b_2\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $x$ é o vetor de entrada de dimensão $d_{\\text{model}}$,\n",
        "- $W_1 \\in \\mathbb{R}^{d_{\\text{ff}} \\times d_{\\text{model}}}$ e $W_2 \\in \\mathbb{R}^{d_{\\text{model}} \\times d_{\\text{ff}}}$ são pesos aprendidos,\n",
        "- $d_{\\text{ff}}$ é a dimensionalidade intermediária (maior que $d_{\\text{model}}$ para aumentar a capacidade do modelo),\n",
        "- $\\text{ReLU}(x) = \\max(0, x)$ é a função de ativação não-linear.\n",
        "\n",
        "Essa camada é aplicada posição a posição (de forma independente em cada token), e introduz não-linearidades e capacidade de transformação mais complexa ao modelo, além de expandir e comprimir a dimensionalidade, o que funciona como um \"bottleneck\" informativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kc5gpf2V6cSY"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.dropout(self.relu(self.fc1(x))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVXrO_tjYkPp",
        "outputId": "66867038-c4bc-4bca-b424-b5991c120594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 5, 512])\n",
            "Output shape: torch.Size([2, 5, 512])\n"
          ]
        }
      ],
      "source": [
        "# Exemplo\n",
        "d_model = 512\n",
        "d_ff = 2048\n",
        "B, T = 2, 5\n",
        "\n",
        "feed_forward = FeedForward(d_model, d_ff)\n",
        "\n",
        "query = torch.randn(B, T, d_model)  # (B, T, d_model)\n",
        "output = feed_forward(query)\n",
        "\n",
        "print(f'Input shape: {query.shape}')  # Input shape: (B, T, d_model)\n",
        "print(f'Output shape: {output.shape}')  # Output shape: (B, T, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1jfR3WMYkPp"
      },
      "source": [
        "### EncoderLayer e Encoder\n",
        "\n",
        "Cada `EncoderLayer` é composta por dois blocos: atenção multi-cabeça seguida de normalização, e uma feed-forward seguida de outra normalização. Em ambos os casos, há conexões residuais e dropout:\n",
        "\n",
        "$$\n",
        "x_1 = \\text{LayerNorm}(x + \\text{Dropout}(\\text{MultiHead}(x, x, x)))\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Output} = \\text{LayerNorm}(x_1 + \\text{Dropout}(\\text{FFN}(x_1)))\n",
        "$$\n",
        "\n",
        "A classe `Encoder` empilha múltiplas `EncoderLayer`s após converter os tokens com `Embedding` e adicionar codificações posicionais. O fluxo é:\n",
        "\n",
        "$$\n",
        "x = \\text{Embedding}(x) + \\text{PositionalEncoding}\n",
        "$$\n",
        "\n",
        "$$\n",
        "x = \\text{EncoderLayer}_N \\circ \\cdots \\circ \\text{EncoderLayer}_1 (x)\n",
        "$$\n",
        "\n",
        "Esse processo transforma a sequência de entrada em uma representação contextualizada, onde cada posição é influenciada pelas demais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ce-MVk6t6eSl"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward  = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        # Self-Attention\n",
        "        attn_out = self.self_attn(x, x, x, mask=src_mask)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # FeedForward\n",
        "        ff_out = self.feed_forward(x)\n",
        "        x = x + self.dropout(ff_out)\n",
        "        x = self.norm2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWw4njPgYkPq",
        "outputId": "dabb5cfc-504a-4402-c51b-53d96aeb05a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 10, 32])\n",
            "Output shape: torch.Size([4, 10, 32])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "\n",
        "encoder_layer = EncoderLayer(d_model, num_heads, d_ff)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "seq_len = 10\n",
        "\n",
        "x = torch.randn(batch_size, seq_len, d_model)\n",
        "out = encoder_layer(x)\n",
        "\n",
        "print(f\"Input shape: {x.shape}\")    # (N, T, d_model)\n",
        "print(f\"Output shape: {out.shape}\") # (N, T, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o5K1EaNm6gLT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(d_model, num_heads, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPInJxI1YkPr",
        "outputId": "7d55b248-94f7-4d6f-dae0-41ed01c849a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 12, 32])\n",
            "Encoder output: torch.Size([4, 12, 32])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "num_layers = 3\n",
        "\n",
        "encoder = Encoder(d_model, num_heads, d_ff, num_layers)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "seq_len = 12\n",
        "\n",
        "x = torch.randn(batch_size, seq_len, d_model)\n",
        "out = encoder(x)\n",
        "\n",
        "print(f\"Input shape: {x.shape}\")     # (N, T, d_model)\n",
        "print(f\"Encoder output: {out.shape}\") # (N, T, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr2J9yPEYkPr"
      },
      "source": [
        "### DecoderLayer e Decoder\n",
        "\n",
        "Cada `DecoderLayer` possui três blocos com conexões residuais e normalização:\n",
        "\n",
        "1. **Self-attention mascarada**: impede que o token atual veja os futuros.\n",
        "2. **Cross-attention**: permite que o decoder atenda à saída do encoder.\n",
        "3. **Feed-forward**: transformação não linear local.\n",
        "\n",
        "As operações são:\n",
        "\n",
        "$$\n",
        "x_1 = \\text{LayerNorm}(x + \\text{Dropout}(\\text{SelfAttn}(x)))\n",
        "$$\n",
        "\n",
        "$$\n",
        "x_2 = \\text{LayerNorm}(x_1 + \\text{Dropout}(\\text{CrossAttn}(x_1, \\text{enc\\_out})))\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Output} = \\text{LayerNorm}(x_2 + \\text{Dropout}(\\text{FFN}(x_2)))\n",
        "$$\n",
        "\n",
        "O `Decoder` empilha múltiplas `DecoderLayer`s após aplicar embedding e codificação posicional, e gera uma distribuição sobre o vocabulário via uma camada linear final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K4uVsly1YkPr"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1, cross_attention=True):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attention = cross_attention\n",
        "        if cross_attention:\n",
        "            self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model) if cross_attention else None\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_out=None, tgt_mask=None, memory_mask=None):\n",
        "        # Masked Self-Attention\n",
        "        attn_out = self.self_attn(x, x, x, mask=tgt_mask)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Cross-Attention (se habilitado)\n",
        "        if self.cross_attention and enc_out is not None:\n",
        "            attn_out = self.cross_attn(x, enc_out, enc_out, mask=memory_mask)\n",
        "            x = x + self.dropout(attn_out)\n",
        "            x = self.norm2(x)\n",
        "\n",
        "        # FeedForward\n",
        "        ff_out = self.feed_forward(x)\n",
        "        x = x + self.dropout(ff_out)\n",
        "        x = self.norm3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-L7L_e2YkPr",
        "outputId": "909748f8-a075-41b0-c48b-811a2a0d096a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target input: torch.Size([4, 7, 32])\n",
            "DecoderLayer output: torch.Size([4, 7, 32])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "\n",
        "decoder_layer = DecoderLayer(d_model, num_heads, d_ff)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "src_len = 15\n",
        "tgt_len = 7\n",
        "\n",
        "enc_out = torch.randn(batch_size, src_len, d_model)  # saída do encoder\n",
        "tgt = torch.randn(batch_size, tgt_len, d_model)      # entrada do decoder\n",
        "\n",
        "tgt_mask = causal_mask(tgt_len)\n",
        "\n",
        "out = decoder_layer(tgt, enc_out, tgt_mask=tgt_mask)\n",
        "\n",
        "print(f\"Target input: {tgt.shape}\")        # (N, T_tgt, d_model)\n",
        "print(f\"DecoderLayer output: {out.shape}\") # (N, T_tgt, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "waEx9H5uYkPr"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1, cross_attention=True):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(d_model, num_heads, d_ff, dropout, cross_attention)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, enc_out=None, tgt_mask=None, memory_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_out, tgt_mask, memory_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKh_uqOnYkPr",
        "outputId": "191bafcb-7f85-40b3-b29e-98690d33c5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder input: torch.Size([4, 7, 32])\n",
            "Decoder output: torch.Size([4, 7, 32])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "num_layers = 2\n",
        "\n",
        "decoder = Decoder(d_model, num_heads, d_ff, num_layers)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "src_len = 15\n",
        "tgt_len = 7\n",
        "\n",
        "enc_out = torch.randn(batch_size, src_len, d_model)\n",
        "tgt = torch.randn(batch_size, tgt_len, d_model)\n",
        "\n",
        "tgt_mask = causal_mask(tgt_len)\n",
        "\n",
        "out = decoder(tgt, enc_out, tgt_mask=tgt_mask)\n",
        "\n",
        "print(f\"Decoder input: {tgt.shape}\")     # (N, T_tgt, d_model)\n",
        "print(f\"Decoder output: {out.shape}\")    # (N, T_tgt, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxRwIQ57YkPr"
      },
      "source": [
        "### Transformer\n",
        "\n",
        "A classe `Transformer` combina o encoder e o decoder em uma arquitetura completa de tradução seq2seq. Ela segue o formato proposto por Vaswani et al. (2017), onde:\n",
        "\n",
        "- O **encoder** processa a sequência de entrada e gera representações contextuais.\n",
        "- O **decoder** gera a saída passo a passo, utilizando essas representações.\n",
        "\n",
        "#### Máscaras\n",
        "\n",
        "Durante o `forward`, são geradas duas máscaras:\n",
        "- **Máscara de padding**: impede atenção a tokens vazios (`src == 0` ou `trg == 0`).\n",
        "- **Máscara causal (no-peak)**: impede que a atenção no decoder veja posições futuras, garantindo autoregressividade. Ela é definida por:\n",
        "\n",
        "$$\n",
        "\\text{nopeak}_{i,j} = \\begin{cases}\n",
        "1, & \\text{se } j \\leq i \\\\\n",
        "0, & \\text{caso contrário}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "O fluxo geral é:\n",
        "\n",
        "$$\n",
        "\\text{EncoderOutput} = \\text{Encoder}(src, src\\_mask)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Output} = \\text{Decoder}(trg, \\text{EncoderOutput}, src\\_mask, trg\\_mask)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cQXwbJWEYkPs"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_encoder_layers, num_decoder_layers,\n",
        "                 src_vocab_size, tgt_vocab_size, max_len=5000, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # embeddings separados\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # positional encoding\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "        # encoder e decoder\n",
        "        self.encoder = Encoder(d_model, num_heads, d_ff, num_encoder_layers, dropout)\n",
        "        self.decoder = Decoder(d_model, num_heads, d_ff, num_decoder_layers, dropout)\n",
        "\n",
        "        # projeção final para o vocabulário de saída\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, memory_mask=None):\n",
        "        \"\"\"\n",
        "        src: (N, T_src) índices dos tokens da entrada\n",
        "        tgt: (N, T_tgt) índices dos tokens da saída\n",
        "        \"\"\"\n",
        "        # embeddings + posições\n",
        "        src_emb = self.src_embedding(src) * (self.src_embedding.embedding_dim ** 0.5)\n",
        "        src_emb = self.pos_encoding(src_emb)\n",
        "\n",
        "        tgt_emb = self.tgt_embedding(tgt) * (self.tgt_embedding.embedding_dim ** 0.5)\n",
        "        tgt_emb = self.pos_encoding(tgt_emb)\n",
        "\n",
        "        # encoder\n",
        "        memory = self.encoder(src_emb, src_mask)\n",
        "\n",
        "        # decoder\n",
        "        out = self.decoder(tgt_emb, memory, tgt_mask, memory_mask)\n",
        "\n",
        "        # projeção final para vocabulário alvo\n",
        "        logits = self.fc_out(out)  # (N, T_tgt, tgt_vocab_size)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl-mQ91JYkPs",
        "outputId": "9919a31d-8d88-4ea3-9c77-a7321927aa9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source input shape: torch.Size([4, 12])\n",
            "Target input shape: torch.Size([4, 8])\n",
            "Output shape: torch.Size([4, 8, 150])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "num_encoder_layers = 2\n",
        "num_decoder_layers = 2\n",
        "src_vocab_size = 120   # ex: português\n",
        "tgt_vocab_size = 150   # ex: inglês\n",
        "max_len = 50\n",
        "\n",
        "model = Transformer(d_model, num_heads, d_ff, num_encoder_layers, num_decoder_layers, src_vocab_size, tgt_vocab_size, max_len)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "src_len = 12\n",
        "tgt_len = 8\n",
        "\n",
        "src = torch.randint(0, src_vocab_size, (batch_size, src_len))  # tokens de entrada\n",
        "tgt = torch.randint(0, tgt_vocab_size, (batch_size, tgt_len))  # tokens de saída\n",
        "\n",
        "tgt_mask = causal_mask(tgt_len)\n",
        "\n",
        "out = model(src, tgt, tgt_mask=tgt_mask)\n",
        "\n",
        "print(f\"Source input shape: {src.shape}\")   # (N, T_src)\n",
        "print(f\"Target input shape: {tgt.shape}\")   # (N, T_tgt)\n",
        "print(f\"Output shape: {out.shape}\")         # (N, T_tgt, tgt_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zoj14w6_YkPs"
      },
      "source": [
        "## Tradução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EK-iYWL2YkPs"
      },
      "outputs": [],
      "source": [
        "pairs = [\n",
        "    (\"olá\", \"hello\"),\n",
        "    (\"bom dia\", \"good morning\"),\n",
        "    (\"boa noite\", \"good night\"),\n",
        "    (\"como vai?\", \"how are you?\"),\n",
        "    (\"estou bem\", \"i am fine\"),\n",
        "    (\"obrigado\", \"thank you\"),\n",
        "    (\"até logo\", \"see you later\"),\n",
        "    (\"sim\", \"yes\"),\n",
        "    (\"não\", \"no\"),\n",
        "    (\"eu gosto de café\", \"i like coffee\"),\n",
        "    (\"ela gosta de música\", \"she likes music\"),\n",
        "    (\"nós vamos para a escola\", \"we go to school\"),\n",
        "    (\"ele está em casa\", \"he is at home\"),\n",
        "    (\"onde você está?\", \"where are you?\"),\n",
        "    (\"o gato está na cadeira\", \"the cat is on the chair\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OHGugAY2YkPt"
      },
      "outputs": [],
      "source": [
        "def build_vocab(sentences):\n",
        "    tokens = set()\n",
        "    for s in sentences:\n",
        "        tokens.update(s.lower().split())\n",
        "    stoi = {tok: i+4 for i, tok in enumerate(sorted(tokens))}\n",
        "    stoi[\"<pad>\"] = 0\n",
        "    stoi[\"<sos>\"] = 1\n",
        "    stoi[\"<eos>\"] = 2\n",
        "    stoi[\"<unk>\"] = 3\n",
        "    itos = {i: t for t, i in stoi.items()}\n",
        "    return stoi, itos\n",
        "\n",
        "# constrói vocabulários\n",
        "src_sentences = [pt for pt, en in pairs]\n",
        "tgt_sentences = [en for pt, en in pairs]\n",
        "\n",
        "src_stoi, src_itos = build_vocab(src_sentences)\n",
        "tgt_stoi, tgt_itos = build_vocab(tgt_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBv4csrWYkPt",
        "outputId": "6d94e664-437e-47b8-dc75-bfe4c4fefa8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_data: torch.Size([15, 10])\n",
            "tgt_data: torch.Size([15, 10])\n"
          ]
        }
      ],
      "source": [
        "def encode_sentence(sentence, stoi, max_len=10):\n",
        "    tokens = sentence.lower().split()\n",
        "    ids = [stoi.get(tok, stoi[\"<unk>\"]) for tok in tokens]\n",
        "    ids = [stoi[\"<sos>\"]] + ids + [stoi[\"<eos>\"]]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [stoi[\"<pad>\"]] * (max_len - len(ids))\n",
        "    return ids[:max_len]\n",
        "\n",
        "max_len = 10\n",
        "data = [\n",
        "    (encode_sentence(pt, src_stoi, max_len), encode_sentence(en, tgt_stoi, max_len))\n",
        "    for pt, en in pairs\n",
        "]\n",
        "\n",
        "src_data = torch.tensor([pt for pt, en in data])\n",
        "tgt_data = torch.tensor([en for pt, en in data])\n",
        "\n",
        "print(\"src_data:\", src_data.shape)  # (N, max_len)\n",
        "print(\"tgt_data:\", tgt_data.shape)  # (N, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2o4r36g_YkPt"
      },
      "outputs": [],
      "source": [
        "src_vocab_size = len(src_stoi)\n",
        "tgt_vocab_size = len(tgt_stoi)\n",
        "\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "num_encoder_layers = 2\n",
        "num_decoder_layers = 2\n",
        "\n",
        "model = Transformer(\n",
        "    d_model, num_heads, d_ff,\n",
        "    num_encoder_layers, num_decoder_layers,\n",
        "    src_vocab_size, tgt_vocab_size, max_len\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3s_MGZ8YkPt",
        "outputId": "f08dbc63-1bf0-425c-eb33-0b893bbeb87c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 9.5385\n",
            "Epoch 20, Loss: 5.4852\n",
            "Epoch 30, Loss: 3.0890\n",
            "Epoch 40, Loss: 1.8745\n",
            "Epoch 50, Loss: 1.2227\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=tgt_stoi[\"<pad>\"])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 4\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for i in range(0, len(src_data), batch_size):\n",
        "        src_batch = src_data[i:i+batch_size]\n",
        "        tgt_batch = tgt_data[i:i+batch_size]\n",
        "\n",
        "        # entrada do decoder é sem o último token\n",
        "        tgt_in = tgt_batch[:, :-1]\n",
        "        # alvo é sem o primeiro token\n",
        "        tgt_out = tgt_batch[:, 1:]\n",
        "\n",
        "        tgt_mask = causal_mask(tgt_in.size(1))\n",
        "\n",
        "        logits = model(src_batch, tgt_in, tgt_mask=tgt_mask)\n",
        "\n",
        "        loss = criterion(\n",
        "            logits.reshape(-1, tgt_vocab_size),\n",
        "            tgt_out.reshape(-1)\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2BRTHXUYkPt",
        "outputId": "15ee7c6d-5103-4dd0-f4f1-fdd249609970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> i like coffee <eos>\n"
          ]
        }
      ],
      "source": [
        "def greedy_translate(model, src_sentence, max_len=10):\n",
        "    model.eval()\n",
        "    src_ids = torch.tensor([encode_sentence(src_sentence, src_stoi, max_len)])\n",
        "    tgt_ids = torch.tensor([[tgt_stoi[\"<sos>\"]]])\n",
        "\n",
        "    for _ in range(max_len-1):\n",
        "        tgt_mask = causal_mask(tgt_ids.size(1))\n",
        "        logits = model(src_ids, tgt_ids, tgt_mask=tgt_mask)\n",
        "        next_token = logits[:, -1, :].argmax(-1).unsqueeze(0)\n",
        "        tgt_ids = torch.cat([tgt_ids, next_token], dim=1)\n",
        "        if next_token.item() == tgt_stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    return \" \".join([tgt_itos[i.item()] for i in tgt_ids[0]])\n",
        "\n",
        "print(greedy_translate(model, \"eu gosto de cafe\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlv2XZvSYkPt"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQaGjBRsYkPu"
      },
      "source": [
        "### Exercício 1: Classificação de Notícias com Transformer Encoder\n",
        "\n",
        "Implemente um módulo de classificação de texto utilizando **apenas o Encoder do Transformer**.  \n",
        "\n",
        "O modelo deve:  \n",
        "- Receber uma sequência de índices de tokens como entrada.  \n",
        "- Passar os embeddings pela pilha de camadas do Encoder.  \n",
        "- Agregar a informação da sequência por meio de um **pooling de média na dimensão temporal** (`seq_len`).  \n",
        "- Passar o vetor resultante por uma camada linear para prever a classe.  \n",
        "\n",
        "O dataset a ser utilizado é o **20 Newsgroups**, filtrado em algumas categorias de notícias.  \n",
        "Seu objetivo é treinar o classificador para prever a qual categoria pertence cada texto.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GiCrxFnFYkPu"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = ['sci.electronics', 'comp.graphics', 'sci.med', 'rec.motorcycles']\n",
        "max_len = 100\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# === Carregamento dos dados ===\n",
        "newsgroups_data = fetch_20newsgroups(subset='all', categories=categories)\n",
        "texts = newsgroups_data.data[:5000]\n",
        "labels = newsgroups_data.target[:5000]\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# === Pré-processamento ===\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def build_vocab(texts, min_freq=1):\n",
        "    word_freq = {}\n",
        "    for text in texts:\n",
        "        tokens = preprocess_text(text)\n",
        "        for token in tokens:\n",
        "            word_freq[token] = word_freq.get(token, 0) + 1\n",
        "\n",
        "    vocab = {'<pad>': 0, '<unk>': 1}\n",
        "    index = 2\n",
        "    for word, freq in word_freq.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = index\n",
        "            index += 1\n",
        "    return vocab\n",
        "\n",
        "\n",
        "# === Vocabulário ===\n",
        "vocab = build_vocab(train_texts)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "\n",
        "# === Dataset ===\n",
        "class NewsGroupsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocab, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        tokens = preprocess_text(text)\n",
        "        token_ids = [self.vocab.get(token, self.vocab['<unk>']) for token in tokens]\n",
        "        if len(token_ids) > self.max_len:\n",
        "            token_ids = token_ids[:self.max_len]\n",
        "        else:\n",
        "            token_ids += [self.vocab['<pad>']] * (self.max_len - len(token_ids))\n",
        "        return torch.tensor(token_ids, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        token_ids = self.encode_text(text)\n",
        "        return token_ids, label\n",
        "\n",
        "\n",
        "# === DataLoaders ===\n",
        "train_dataset = NewsGroupsDataset(train_texts, train_labels, vocab, max_len)\n",
        "val_dataset = NewsGroupsDataset(val_texts, val_labels, vocab, max_len)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TSFItWXkYkPu"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes, d_model, num_heads, d_ff, num_layers, max_len=100, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
        "        self.fc_out = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        # 1. Embeddings e Positional Encoding\n",
        "        x = self.embedding(x) * math.sqrt(self.embedding.embedding_dim)\n",
        "        x = self.pos_encoding(x)\n",
        "\n",
        "        # 2. Passa pelo Encoder\n",
        "        encoder_out = self.encoder(x, src_mask)\n",
        "\n",
        "        # 3. Pooling de Média\n",
        "        # Reduz a dimensão de tokens para um único vetor (seq_len -> 1)\n",
        "        # O resultado é um vetor que representa a média de todos os tokens.\n",
        "        pooled_output = torch.mean(encoder_out, dim=1)\n",
        "\n",
        "        # 4. Classificador Linear\n",
        "        logits = self.fc_out(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Parâmetros do Modelo e Treinamento ===\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "d_ff = 256\n",
        "num_encoder_layers = 2\n",
        "num_classes = len(categories)\n",
        "\n",
        "model = TransformerClassifier(\n",
        "    vocab_size,\n",
        "    num_classes,\n",
        "    d_model,\n",
        "    num_heads,\n",
        "    d_ff,\n",
        "    num_encoder_layers,\n",
        "    max_len\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "epochs = 10\n",
        "print(f\"Iniciando treinamento com {epochs} épocas...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # --- Treinamento ---\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_preds = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for texts, labels in train_dataloader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Gera a máscara de padding para ignorar tokens <pad>\n",
        "        src_mask = (texts != vocab['<pad>']).unsqueeze(1).unsqueeze(2).to(device)\n",
        "\n",
        "        logits = model(texts, src_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct_preds += (preds == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    train_loss = total_loss / len(train_dataloader)\n",
        "    train_acc = correct_preds / total_samples\n",
        "\n",
        "    # --- Validação ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct_preds = 0\n",
        "    val_total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_dataloader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "\n",
        "            src_mask = (texts != vocab['<pad>']).unsqueeze(1).unsqueeze(2).to(device)\n",
        "\n",
        "            logits = model(texts, src_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            val_correct_preds += (preds == labels).sum().item()\n",
        "            val_total_samples += labels.size(0)\n",
        "\n",
        "    val_loss /= len(val_dataloader)\n",
        "    val_acc = val_correct_preds / val_total_samples\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "          f\"Treino - Perda: {train_loss:.4f}, Acurácia: {train_acc:.4f} | \"\n",
        "          f\"Validação - Perda: {val_loss:.4f}, Acurácia: {val_acc:.4f}\")\n",
        "\n",
        "print(\"Treinamento finalizado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jymlL_cxZ1DG",
        "outputId": "b1bcb27d-47f5-442d-9b13-681480b91990"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando treinamento com 10 épocas...\n",
            "Epoch 1/10 | Treino - Perda: 1.2612, Acurácia: 0.4096 | Validação - Perda: 0.9890, Acurácia: 0.5792\n",
            "Epoch 2/10 | Treino - Perda: 0.6952, Acurácia: 0.7267 | Validação - Perda: 0.6815, Acurácia: 0.7389\n",
            "Epoch 3/10 | Treino - Perda: 0.3529, Acurácia: 0.8719 | Validação - Perda: 0.7604, Acurácia: 0.7579\n",
            "Epoch 4/10 | Treino - Perda: 0.1776, Acurácia: 0.9363 | Validação - Perda: 0.8017, Acurácia: 0.7769\n",
            "Epoch 5/10 | Treino - Perda: 0.1062, Acurácia: 0.9667 | Validação - Perda: 0.9054, Acurácia: 0.7769\n",
            "Epoch 6/10 | Treino - Perda: 0.0489, Acurácia: 0.9854 | Validação - Perda: 0.9762, Acurácia: 0.7833\n",
            "Epoch 7/10 | Treino - Perda: 0.0339, Acurácia: 0.9883 | Validação - Perda: 1.0104, Acurácia: 0.7997\n",
            "Epoch 8/10 | Treino - Perda: 0.0208, Acurácia: 0.9940 | Validação - Perda: 1.0923, Acurácia: 0.7757\n",
            "Epoch 9/10 | Treino - Perda: 0.0764, Acurácia: 0.9737 | Validação - Perda: 1.1627, Acurácia: 0.7693\n",
            "Epoch 10/10 | Treino - Perda: 0.0909, Acurácia: 0.9702 | Validação - Perda: 0.9111, Acurácia: 0.8023\n",
            "Treinamento finalizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM8TdM5hYkPu",
        "outputId": "56a18d3a-b57e-4da6-89c6-06f696f267dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 | Train Loss: 111.791, Train Acc: 0.493 | Val Loss: 19.370, Val Acc: 0.681\n",
            "Epoch 2/15 | Train Loss: 56.078, Train Acc: 0.778 | Val Loss: 15.199, Val Acc: 0.767\n",
            "Epoch 3/15 | Train Loss: 29.132, Train Acc: 0.897 | Val Loss: 18.128, Val Acc: 0.766\n",
            "Epoch 4/15 | Train Loss: 19.933, Train Acc: 0.926 | Val Loss: 16.588, Val Acc: 0.800\n",
            "Epoch 5/15 | Train Loss: 14.128, Train Acc: 0.949 | Val Loss: 14.585, Val Acc: 0.820\n",
            "Epoch 6/15 | Train Loss: 10.791, Train Acc: 0.963 | Val Loss: 17.124, Val Acc: 0.810\n",
            "Epoch 7/15 | Train Loss: 5.893, Train Acc: 0.978 | Val Loss: 18.642, Val Acc: 0.824\n",
            "Epoch 8/15 | Train Loss: 10.928, Train Acc: 0.961 | Val Loss: 20.945, Val Acc: 0.785\n",
            "Epoch 9/15 | Train Loss: 6.876, Train Acc: 0.976 | Val Loss: 16.834, Val Acc: 0.830\n",
            "Epoch 10/15 | Train Loss: 3.472, Train Acc: 0.988 | Val Loss: 20.399, Val Acc: 0.828\n",
            "Epoch 11/15 | Train Loss: 7.087, Train Acc: 0.973 | Val Loss: 18.249, Val Acc: 0.824\n",
            "Epoch 12/15 | Train Loss: 4.470, Train Acc: 0.984 | Val Loss: 18.494, Val Acc: 0.838\n",
            "Epoch 13/15 | Train Loss: 4.041, Train Acc: 0.988 | Val Loss: 19.180, Val Acc: 0.843\n",
            "Epoch 14/15 | Train Loss: 6.671, Train Acc: 0.977 | Val Loss: 21.640, Val Acc: 0.792\n",
            "Epoch 15/15 | Train Loss: 5.649, Train Acc: 0.977 | Val Loss: 17.398, Val Acc: 0.856\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Parâmetros de treino\n",
        "num_epochs = 15\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "d_ff = 256\n",
        "num_encoder_layers = 2\n",
        "num_classes = len(categories)\n",
        "\n",
        "# Adicione a definição da variável 'lr' aqui\n",
        "lr = 0.001  # Exemplo de valor para a taxa de aprendizado\n",
        "\n",
        "# Inicialização do modelo, perda e otimizador\n",
        "model = TransformerClassifier(\n",
        "    vocab_size, num_classes, d_model, num_heads, d_ff, num_encoder_layers\n",
        ").to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Loop de treno\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Métricas\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # Validação\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss: {total_loss:.3f}, Train Acc: {train_acc:.3f} | \"\n",
        "          f\"Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th3BIQnNYkPu"
      },
      "source": [
        "### Exercício 2: Modelo de Linguagem com Transformer Decoder\n",
        "\n",
        "Implemente um **modelo de linguagem baseado apenas no Decoder do Transformer** (estilo *decoder-only*).  \n",
        "\n",
        "O modelo deve:  \n",
        "- Receber uma sequência de tokens como entrada.  \n",
        "- Utilizar máscara **causal** na auto-atenção, garantindo que cada posição só acesse os tokens anteriores e o próprio token.  \n",
        "- Prever o **próximo token em cada posição** (treinamento por *next token prediction*).  \n",
        "\n",
        "O corpus de treino será o fornecido na variável `corpus`.  \n",
        "Seu objetivo é treinar o modelo para gerar frases coerentes em português a partir de um prompt inicial.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVnMkzsVYkPu",
        "outputId": "cdf8afd7-2382-4ca3-c818-80a00ada73ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do corpus: 30000\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def load_corpus_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # dispara erro se a requisição falhar\n",
        "    text = response.text\n",
        "    return text\n",
        "\n",
        "# Exemplo de uso\n",
        "url = \"https://raw.githubusercontent.com/wess/iotr/master/lotr.txt\"\n",
        "corpus = load_corpus_from_url(url)[:30000]\n",
        "\n",
        "print(\"Tamanho do corpus:\", len(corpus))\n",
        "\n",
        "# Tokenize o texto\n",
        "tokens = re.findall(r'\\b\\w+\\b', corpus.lower())\n",
        "\n",
        "# Constrói o vocabulário\n",
        "word_counts = Counter(tokens)\n",
        "vocab = sorted(word_counts.keys())\n",
        "\n",
        "special_tokens = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
        "word2idx = {tok: idx for idx, tok in enumerate(special_tokens, start=0)}\n",
        "\n",
        "for word in vocab:\n",
        "    if word not in word2idx:  # evita colisão\n",
        "        word2idx[word] = len(word2idx)\n",
        "\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "vocab_size = len(word2idx)\n",
        "\n",
        "# Converte tokens para índices\n",
        "indices = [word2idx.get(w, word2idx[\"<unk>\"]) for w in tokens]\n",
        "\n",
        "# Gera as sequências\n",
        "sequence_length = 10\n",
        "inputs, targets = [], []\n",
        "\n",
        "for i in range(len(indices) - seq_len):\n",
        "    seq = indices[i:i+seq_len]\n",
        "    tgt = indices[i+1:i+seq_len+1]\n",
        "\n",
        "    # insere <sos> no início do input, <eos> no fim do target\n",
        "    seq = [word2idx[\"<sos>\"]] + seq\n",
        "    tgt = tgt + [word2idx[\"<eos>\"]]\n",
        "\n",
        "    inputs.append(seq)\n",
        "    targets.append(tgt)\n",
        "\n",
        "inputs = torch.tensor(inputs, dtype=torch.long)\n",
        "targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "# Cria o dataset e o dataloader\n",
        "batch_size = 32\n",
        "dataset = TensorDataset(inputs, targets)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tmOWXK3vYkPu"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# Reutilizando as classes PositionalEncoding e Decoder que já foram definidas\n",
        "# (Assumindo que estão disponíveis no ambiente)\n",
        "\n",
        "class TransformerDecoderLM(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, d_ff, num_layers, max_len=100, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout, cross_attention=False)\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, tgt_mask=None):\n",
        "        # 1. Embeddings e Positional Encoding\n",
        "        x = self.embedding(x) * math.sqrt(self.embedding.embedding_dim)\n",
        "        x = self.pos_encoding(x)\n",
        "\n",
        "        # 2. Passa pelo Decoder (sem cross-attention, já que não há Encoder)\n",
        "        decoder_out = self.decoder(x, tgt_mask=tgt_mask)\n",
        "\n",
        "        # 3. Projeção para o vocabulário\n",
        "        logits = self.fc_out(decoder_out)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# === Parâmetros do Modelo e Treinamento ===\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "d_ff = 256\n",
        "num_layers = 2\n",
        "max_len = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = TransformerDecoderLM(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    d_ff=d_ff,\n",
        "    num_layers=num_layers,\n",
        "    max_len=max_len\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word2idx[\"<pad>\"])\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "num_epochs = 10\n",
        "print(f\"Iniciando treinamento com {num_epochs} épocas...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Geração da máscara causal para o decoder\n",
        "        tgt_mask = (causal_mask(inputs.size(1)) == 0).unsqueeze(0).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs, tgt_mask)\n",
        "\n",
        "        # reshape para calcular a perda\n",
        "        loss = criterion(\n",
        "            outputs.view(-1, outputs.size(-1)),\n",
        "            targets.view(-1)\n",
        "        )\n",
        "\n",
        "        # Backward pass e otimização\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Perda: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"Treinamento finalizado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPNxWGLMa2VP",
        "outputId": "ba7e683e-8d69-4f78-926e-8f9e7420b447"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando treinamento com 10 épocas...\n",
            "Epoch 1/10, Perda: nan\n",
            "Epoch 2/10, Perda: nan\n",
            "Epoch 3/10, Perda: nan\n",
            "Epoch 4/10, Perda: nan\n",
            "Epoch 5/10, Perda: nan\n",
            "Epoch 6/10, Perda: nan\n",
            "Epoch 7/10, Perda: nan\n",
            "Epoch 8/10, Perda: nan\n",
            "Epoch 9/10, Perda: nan\n",
            "Epoch 10/10, Perda: nan\n",
            "Treinamento finalizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "P_ZI3HqqYkPu",
        "outputId": "89a60002-e284-49a6-da6c-1907938f8da9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3133138287.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# epochs = 20\n",
        "# for epoch in range(epochs):\n",
        "#     total_loss = 0\n",
        "#     for x, y in dataloader:\n",
        "#         x, y = x.to(device), y.to(device)\n",
        "#         mask = causal_mask(x.size(1)).to(device)\n",
        "#         logits = model(x, mask=mask)\n",
        "#         loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         total_loss += loss.item()\n",
        "#     print(f\"Epoch {epoch+1}, Loss: {total_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "EwLVc56gYkPu"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, prompt, word2idx, idx2word, max_new_tokens=20, device=\"cpu\"):\n",
        "    model.eval()\n",
        "\n",
        "    # Converte prompt em índices\n",
        "    tokens = re.findall(r'\\b\\w+\\b', prompt.lower())\n",
        "    ids = torch.tensor([[word2idx.get(tok, word2idx[\"<unk>\"]) for tok in tokens]], device=device)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Máscara causal\n",
        "        mask = causal_mask(ids.size(1)).to(device)\n",
        "\n",
        "        # Forward\n",
        "        with torch.no_grad():\n",
        "            logits = model(ids, mask=mask)  # (1, T, vocab_size)\n",
        "\n",
        "        # Pega último token previsto (greedy)\n",
        "        next_id = logits[:, -1, :].argmax(-1).unsqueeze(0)\n",
        "\n",
        "        # Concatena ao input\n",
        "        ids = torch.cat([ids, next_id], dim=1)\n",
        "\n",
        "    # Decodifica para palavras\n",
        "    out_tokens = [idx2word[i.item()] for i in ids[0]]\n",
        "    return \" \".join(out_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "5uB_ycoMYkPv",
        "outputId": "20015459-ae38-4e56-8e9b-74f8d0ea1426"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2363761727.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1125437497.py\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, prompt, word2idx, idx2word, max_new_tokens, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Converte prompt em índices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\b\\w+\\b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "# prompt = \"the\"\n",
        "# generated = generate_text(model, prompt, word2idx, idx2word, max_new_tokens=10, device=device)\n",
        "# print(\"Generated:\", generated)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}